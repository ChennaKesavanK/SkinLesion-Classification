{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNo1asTMBaC9","outputId":"cd0f6af5-f921-497c-f162-7a678c8f4dd4","executionInfo":{"status":"ok","timestamp":1728125714207,"user_tz":-330,"elapsed":21120,"user":{"displayName":"2016 BALAJI M","userId":"15697558856840379114"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')  # Mounts Google Drive at /content/drive\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1EAzSdZ2osLpMM5w_x2SrIFDDB5s4_p8I"},"outputId":"16653915-9f6a-4bdf-e776-f459ae82c62f","id":"zROsGq9JxEv4","executionInfo":{"status":"ok","timestamp":1728132821703,"user_tz":-330,"elapsed":5612802,"user":{"displayName":"2016 BALAJI M","userId":"15697558856840379114"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tqdm import tqdm  # For progress tracking\n","\n","# Set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Define a basic transform for your images\n","transform = transforms.Compose([\n","    transforms.Resize((224,224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Load images from a folder\n","def load_images_from_folder(folder, transform, limit=None):\n","    images = []\n","    for i, filename in enumerate(os.listdir(folder)):\n","        if limit and i >= limit:  # Limit the number of images loaded\n","            break\n","        img_path = os.path.join(folder, filename)\n","        img = Image.open(img_path)\n","        if transform:\n","            img = transform(img)\n","        images.append(img)\n","    return torch.stack(images)\n","\n","# Folder containing real images\n","image_folder = '/content/drive/My Drive/PRIE/train/Vascular lesion/vascular lesion 4'\n","real_images = load_images_from_folder(image_folder, transform)\n","\n","# Create a DataLoader\n","dataloader = torch.utils.data.DataLoader(real_images, batch_size=32, shuffle=True)\n","\n","# Hyperparameters\n","latent_dim =256\n","lr = 0.0002\n","beta1 = 0.5\n","beta2 = 0.999\n","num_epochs = 1500\n","save_interval = 50  # Generate and display images every 50 epochs\n","save_folder = '/content/drive/My Drive/Dataset/generate 1'\n","\n","# Define the generator\n","# Define the generator with ConvTranspose2d layers for smoother upscaling\n","class Generator(nn.Module):\n","    def __init__(self, latent_dim):\n","        super(Generator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(latent_dim, 1024 * 7 * 7),  # Start with a small feature map\n","            nn.ReLU(),\n","            nn.Unflatten(1, (1024, 7, 7)),  # Shape it into (1024, 7, 7)\n","\n","            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),  # 7x7 -> 14x14\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(),\n","\n","            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),  # 14x14 -> 28x28\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(),\n","\n","            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),  # 28x28 -> 56x56\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(),\n","\n","            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 56x56 -> 112x112\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","\n","            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # 112x112 -> 224x224\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","\n","            nn.Conv2d(32, 3, kernel_size=3, padding=1),  # 224x224 output with 3 channels (RGB)\n","            nn.Tanh()  # Output values in range [-1, 1] for normalized images\n","        )\n","\n","    def forward(self, z):\n","        img = self.model(z)\n","        return img\n","\n","\n","# Define the discriminator\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # 224x224 -> 112x112\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.25),\n","\n","            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 112x112 -> 56x56\n","            nn.BatchNorm2d(128),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.25),\n","\n","            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),  # 56x56 -> 28x28\n","            nn.BatchNorm2d(256),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.25),\n","\n","            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),  # 28x28 -> 14x14\n","            nn.BatchNorm2d(512),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.25),\n","\n","            nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),  # 14x14 -> 7x7\n","            nn.BatchNorm2d(1024),\n","            nn.LeakyReLU(0.2),\n","            nn.Dropout(0.25)\n","        )\n","        self.fc = nn.Linear(1024 * 7 * 7, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, img):\n","        out = self.model(img)\n","        out = out.view(out.size(0), -1)  # Flatten\n","        validity = self.fc(out)\n","        return self.sigmoid(validity)\n","\n","\n","\n","# Define the generator and discriminator\n","generator = Generator(latent_dim).to(device)\n","discriminator = Discriminator().to(device)\n","\n","# Loss function\n","adversarial_loss = nn.BCELoss()\n","\n","# Optimizers\n","optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, beta2))\n","optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, beta2))\n","\n","# Ensure the save folder exists\n","if not os.path.exists(save_folder):\n","    os.makedirs(save_folder)\n","\n","\n","# Real-time image generation function\n","def generate_image(generator, latent_dim, device):\n","    with torch.no_grad():\n","        # Sample random noise for the generator\n","        z = torch.randn(1, latent_dim, device=device)\n","\n","        # Generate a single image (1 image of 224x224 size)\n","        generated_image = generator(z).detach().cpu()\n","\n","        # Denormalize the image from [-1, 1] to [0, 1]\n","        generated_image = (generated_image + 1) / 2.0\n","\n","        # Display the image\n","        plt.figure(figsize=(4, 4))\n","        plt.imshow(np.transpose(generated_image.squeeze().numpy(), (1, 2, 0)))\n","        plt.show()\n","\n","    return generated_image\n","\n","\n","# Training loop\n","for epoch in tqdm(range(num_epochs), desc=\"Training Epochs\"):\n","    for i, real_images in enumerate(dataloader):\n","        real_images = real_images.to(device)\n","\n","        # Adversarial ground truths\n","        valid = torch.ones(real_images.size(0), 1, device=device)\n","        fake = torch.zeros(real_images.size(0), 1, device=device)\n","\n","        # ---------------------\n","        #  Train Discriminator\n","        # ---------------------\n","        optimizer_D.zero_grad()\n","\n","        # Sample noise as generator input\n","        z = torch.randn(real_images.size(0), latent_dim, device=device)\n","        fake_images = generator(z)\n","\n","        # Discriminator losses\n","        real_loss = adversarial_loss(discriminator(real_images), valid)\n","        fake_loss = adversarial_loss(discriminator(fake_images.detach()), fake)\n","        d_loss = (real_loss + fake_loss) / 2\n","        d_loss.backward()\n","        optimizer_D.step()\n","\n","        # -----------------\n","        #  Train Generator\n","        # -----------------\n","        optimizer_G.zero_grad()\n","\n","        # Generator loss\n","        g_loss = adversarial_loss(discriminator(fake_images), valid)\n","        g_loss.backward()\n","        optimizer_G.step()\n","\n","    # Print the losses every 100 epochs for monitoring\n","    if (epoch + 1) % 10 == 0:\n","        print(f\"Epoch [{epoch+1}/{num_epochs}] - Generator Loss: {g_loss.item():.4f}, Discriminator Loss: {d_loss.item():.4f}\")\n","\n","    # Generate and display images every `save_interval` epochs\n","    if (epoch + 1) % save_interval == 0:\n","        with torch.no_grad():\n","            z = torch.randn(16, latent_dim, device=device)\n","            generated_images = generator(z).detach().cpu()\n","\n","            # Denormalize images\n","            generated_images = (generated_images + 1) / 2.0  # Transform from [-1, 1] to [0, 1]\n","\n","            # Display images\n","            grid_img = torchvision.utils.make_grid(generated_images, nrow=4)\n","            plt.figure(figsize=(8, 8))\n","            plt.imshow(np.transpose(grid_img.numpy(), (1, 2, 0)))\n","            plt.show()\n","\n","# Save the final generated images after training completes\n","with torch.no_grad():\n","    num_generated_images = 1000  # You can specify how many images you want to generate\n","    for i in range(num_generated_images // 16):\n","        z = torch.randn(16, latent_dim, device=device)\n","        generated_images = generator(z).detach().cpu()\n","\n","        for j, image in enumerate(generated_images):\n","            img_name = os.path.join(save_folder, f\"generated_{i*16 + j + 1}.png\")\n","            torchvision.utils.save_image(image, img_name, normalize=True)\n","\n","print(f\"All {num_generated_images} images saved to {save_folder}.\")\n","\n","# Call this function to generate an image in real-time\n","generate_image(generator, latent_dim, device)\n"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1_5vu8IKTEJq5RZ7lYM7MDvjSJAXp-WEj","authorship_tag":"ABX9TyOxDZQZ1Depb1vhqTMYTHRR"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}